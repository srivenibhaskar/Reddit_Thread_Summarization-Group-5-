# -*- coding: utf-8 -*-
"""Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-O5_xBLAMGuCeS5xnACAvkDQP6bYGV5d
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.model_selection import train_test_split
from transformers import BartTokenizer, BartForConditionalGeneration, BertTokenizer
from nltk.translate.bleu_score import sentence_bleu
from rouge_score import rouge_scorer
import torch
import nltk
import warnings
warnings.filterwarnings('ignore')

# Download NLTK dependencies
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')


# Define device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Function to clean text
def clean_text(df, slang_dictionary):
    def remove_special_characters(text):
        text = re.sub(r'http\S+|www\S+|@\S+|<.*?>', '', text)  # Remove URLs and HTML tags
        text = re.sub(r'\b\w+@\w+\.\w+\b', '', text)           # Remove email addresses
        text = re.sub(r'@\w+', '', text)                      # Remove usernames
        text = re.sub(r'\bu/\w+\b', '', text)                 # Remove Reddit usernames
        text = re.sub(r'\s*\(\s*', ' ', text)                 # Remove parentheses
        text = re.sub(r'\s*\)\s*', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()              # Remove extra spaces
        return text

    def replace_slangs(text):
        slang_pattern = r'\b(' + '|'.join(re.escape(s) for s in slang_dictionary.keys()) + r')\b'
        return re.sub(slang_pattern, lambda x: slang_dictionary[x.group(0)], text)

    df['document'] = df['document'].apply(remove_special_characters).str.lower().apply(replace_slangs)
    df['summary'] = df['summary'].apply(remove_special_characters).str.lower().apply(replace_slangs)
    return df

# Function to load model and tokenizer
def load_model_and_tokenizer(model_path, tokenizer_path):
    model = BartForConditionalGeneration.from_pretrained(model_path).to(device)
    tokenizer = BartTokenizer.from_pretrained(tokenizer_path)
    return model, tokenizer

# Function to generate summary
def generate_summary(model, tokenizer, text, max_length=150):
    model.eval()
    inputs = tokenizer(text, max_length=1024, truncation=True, return_tensors="pt").to(device)
    summary_ids = model.generate(inputs['input_ids'], max_length=max_length, num_beams=4, length_penalty=2.0)
    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)

# Function to evaluate the model
def evaluate_model(test_df, model, tokenizer, bert_tokenizer):
    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)
    rouge_scores, bleu_scores, bert_f1_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}, [], []

    for _, row in test_df.iterrows():
        generated_summary = generate_summary(model, tokenizer, row['document'])
        reference_summary = row['summary']

        # Calculate ROUGE
        scores = rouge.score(reference_summary, generated_summary)
        for metric in rouge_scores.keys():
            rouge_scores[metric].append(scores[metric].fmeasure)

        # Calculate BLEU
        ref_tokens = nltk.word_tokenize(reference_summary)
        gen_tokens = nltk.word_tokenize(generated_summary)
        bleu_scores.append(sentence_bleu([ref_tokens], gen_tokens))

        # Calculate BERT-based F1
        ref_tokens_bert = bert_tokenizer.tokenize(reference_summary)
        gen_tokens_bert = bert_tokenizer.tokenize(generated_summary)
        common = set(ref_tokens_bert) & set(gen_tokens_bert)
        precision = len(common) / len(gen_tokens_bert) if gen_tokens_bert else 0
        recall = len(common) / len(ref_tokens_bert) if ref_tokens_bert else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        bert_f1_scores.append(f1)

    # Print average scores
    print(f"ROUGE-1: {sum(rouge_scores['rouge1']) / len(rouge_scores['rouge1']):.4f}")
    print(f"ROUGE-2: {sum(rouge_scores['rouge2']) / len(rouge_scores['rouge2']):.4f}")
    print(f"ROUGE-L: {sum(rouge_scores['rougeL']) / len(rouge_scores['rougeL']):.4f}")
    print(f"BLEU: {sum(bleu_scores) / len(bleu_scores):.4f}")
    print(f"BERT F1: {sum(bert_f1_scores) / len(bert_f1_scores):.4f}")

def run_pipeline(folder_path, files_to_join, model_path, tokenizer_path, slang_dictionary, subset_size=5000):
    # Ensure necessary NLTK resources are downloaded
    download_nltk_resources()

    dataframes = []
    for filename in files_to_join:
        if filename.endswith('json'):
            file = pd.read_json(os.path.join(folder_path, filename), lines=True)
            dataframes.append(file)
    df = pd.concat(dataframes, ignore_index=True)

    # Clean data
    df = df.sample(n=subset_size, random_state=42)  # Subset for efficiency
    df = clean_text(df, slang_dictionary)

    # Split data into train and test
    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

    # Load model and tokenizer
    model, tokenizer = load_model_and_tokenizer(model_path, tokenizer_path)
    bert_tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

    # Evaluate model on test set
    evaluate_model(test_df, model, tokenizer, bert_tokenizer)

slang_dictionary = {
    "u": "you",
    "r": "are",
    "cuz": "because",
    "dont": "do not",
    "wont": "will not",
    "im": "I am",
    "yall": "you all",
    "gonna": "going to",
    "gotta": "got to",
    "hafta": "have to",
    "lemme": "let me",
    "kinda": "kind of",
    "sorta": "sort of",
    "lol": "laughing out loud",
    "lmao": "laughing my ass off",
    "btw": "by the way",
    "fyi": "for your information",
    "smh": "shaking my head",
    "idk": "I don't know",
    "ftw": "for the win",
    "brb": "be right back",
    "tbh": "to be honest",
    "wyd": "what you doing",
    "salty": "bitter or upset",
    "simp": "someone who shows excessive sympathy",
    "sus": "suspicious",
    "vibe check": "assessing someone's energy or mood",
    "lit": "exciting or excellent",
    "yeet": "to throw something with force",
    "ghosting": "sudden cut-off communication",
    "shook": "shocked or surprised",
    "extra": "over the top",
    "b4": "before",
    "gtg": "got to go",
    "omg": "oh my god",
    "imo": "in my opinion",
    "tldr": "too long; didn't read",
    "ikr": "I know right",
    "rofl": "rolling on the floor laughing",
    "yolo": "you only live once",
    "ama": "ask me anything",
    "asap": "as soon as possible",
    "nsfw": "not safe for work",
    "afaik": "as far as I know",
    "wtf": "what the f***",
    "irl": "in real life",
    "afk": "away from keyboard",
    "np": "no problem",
    "fr": "for real",
    "srsly": "seriously",
    "fam": "family",
    "flex": "show off",
    "shade": "disrespect",
    "clout": "influence or power",
    "cap/no cap": "lie/no lie",
    "stan": "an obsessive fan",
    "thirsty": "desperate for attention",
    "fomo": "fear of missing out",
    "bussin": "really good",
    "bet": "agreement or approval",
    "cheugy": "out of touch or trying too hard",
}

folder_path = "/content/drive/MyDrive"
files_to_join = ['train.0.json', 'train.1.json']
model_path = '/content/drive/MyDrive/bart_9E9D_model'
tokenizer_path = '/content/drive/MyDrive/bart_9E9D_tokenizer'

run_pipeline(folder_path, files_to_join, model_path, tokenizer_path, slang_dictionary)

